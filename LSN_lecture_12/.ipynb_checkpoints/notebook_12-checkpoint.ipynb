{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e2bc297-6849-4e6c-8557-99ab1a7d36e4",
   "metadata": {},
   "source": [
    "**NOTEBOOK 12**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f672235e-728f-4fc6-b860-c6d10b40baeb",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange\"> Keras - Deep & Convolutional Neural Network image recognition </span>  \n",
    "\n",
    "The goal of exercise 12 is to use deep neural network models (DNN), implemented in the Keras python package, to recognize and distinguish between the ten handwritten digits (0-9).\n",
    "\n",
    "The MNIST dataset comprises $70000$ handwritten digits, each of which comes in a square image, divided into a $28\\times 28$ pixel grid. Every pixel can take on $256$ gradation of the gray color, interpolating between white and black, and hence each data point assumes any value in the set $\\{0,1,\\dots,255\\}$. Since there are $10$ categories in the problem, corresponding to the ten digits, this problem represents a generic **classification task**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a872943-dfee-49b5-8fc5-a849c5af2e1a",
   "metadata": {},
   "source": [
    "### Exercise 12.1\n",
    "\n",
    "<span style=\"color:red\">Change at will and train your DNN by increasing the number of epochs to an adeuqate value</span>. Try to use at least two other optimizers, different from SGD: <span style=\"color:red\">watch to accuracy and loss for training and validation data and comment on the performances</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b2df0a-270b-4b7a-a57c-cb7d49d9410d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 18:55:33.387899: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-27 18:55:33.431979: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-27 18:55:33.432015: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-27 18:55:33.433260: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-27 18:55:33.440374: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-27 18:55:33.440904: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-27 18:55:34.436546: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "seed=0\n",
    "np.random.seed(seed) # fix random seed\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c8ad4d-e01d-48f7-b0ea-fb5ae5bbd20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "Y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28 # number of pixels \n",
    "# output\n",
    "num_classes = 10 # 10 digits\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb881cfa-7a45-4425-bf85-7d4d745a422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 784)\n",
      "X_test shape: (10000, 784)\n",
      "\n",
      "an example of a data point with label 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... and with label [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] after to_categorical\n",
      "\n",
      "X_train shape: (60000, 784)\n",
      "Y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# reshape data, it could depend on Keras backend\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows*img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows*img_cols)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print()\n",
    "\n",
    "# cast to floats\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# rescale data in interval [0,1]\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# look at an example of data point\n",
    "print('an example of a data point with label', Y_train[22])\n",
    "# matshow: display a matrix in a new figure window\n",
    "plt.matshow(X_train[22,:].reshape(28,28),cmap='binary')\n",
    "plt.show()\n",
    "\n",
    "# convert class vectors to binary class matrices, e.g. for use with categorical_crossentropy\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "print('... and with label', Y_train[22], 'after to_categorical')\n",
    "print()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c782ffeb-fc48-41ac-93a5-5137d08b3a13",
   "metadata": {},
   "source": [
    "**Define the Neural Net and its Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f4ece21-df7f-492d-a885-7f20d74192b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture created successfully!\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "def create_DNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(400,input_shape=(img_rows*img_cols,), activation='relu'))\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # soft-max layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "print('Model architecture created successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962505ae-a6af-4268-b892-d3b074b33383",
   "metadata": {},
   "source": [
    "**1-ADADELTA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cbcf82f-dc99-4caf-a2ff-705e3e41f7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully and ready to be trained.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "\n",
    "def compile_model():\n",
    "    # create the model\n",
    "    model=create_DNN()\n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=Adadelta(lr=1.0, rho=0.95,),\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "print('Model compiled successfully and ready to be trained.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3056ea98-9c91-404a-bc14-a465e918dde2",
   "metadata": {},
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a8de4-e111-4284-ab99-c2291f79b094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adadelta.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 18:55:37.255102: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 14s 7ms/step - loss: 2.2653 - acc: 0.1481 - val_loss: 2.1764 - val_acc: 0.2826\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 2.1486 - acc: 0.2229 - val_loss: 2.0542 - val_acc: 0.4319\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 2.0353 - acc: 0.3016 - val_loss: 1.9268 - val_acc: 0.5336\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.9282 - acc: 0.3661 - val_loss: 1.7960 - val_acc: 0.6247\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 1.8193 - acc: 0.4225 - val_loss: 1.6657 - val_acc: 0.6876\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.7151 - acc: 0.4691 - val_loss: 1.5392 - val_acc: 0.7288\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.6129 - acc: 0.5067 - val_loss: 1.4214 - val_acc: 0.7575\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 1.5245 - acc: 0.5422 - val_loss: 1.3146 - val_acc: 0.7826\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 1.4429 - acc: 0.5723 - val_loss: 1.2173 - val_acc: 0.7985\n",
      "Epoch 10/20\n",
      " 423/1875 [=====>........................] - ETA: 8s - loss: 1.3914 - acc: 0.5850"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "# create the deep neural net\n",
    "model_DNN = compile_model()\n",
    "\n",
    "# train DNN and store training info in history\n",
    "history = model_DNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16abc668-dbe7-490e-9d80-1056d8fb9136",
   "metadata": {},
   "source": [
    "**Evaluate the Model Performance on the Unseen Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d0f65-6401-4a13-a392-a31eb7f2664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score = model_DNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# look into training history\n",
    "fig, [ax0, ax1] = plt.subplots(1, 2, figsize=(15 , 6))\n",
    "\n",
    "# summarize history for accuracy\n",
    "ax0.plot(history.history['acc'])\n",
    "ax0.plot(history.history['val_acc'])\n",
    "ax0.set_ylabel('model accuracy')\n",
    "ax0.set_xlabel('epoch')\n",
    "ax0.legend(['train', 'test'], loc='best')\n",
    "ax0.grid()\n",
    "\n",
    "# summarize history for loss\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.plot(history.history['val_loss'])\n",
    "ax1.set_ylabel('model loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train', 'test'], loc='best')\n",
    "ax1.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2010424-d2c3-4c48-827f-4ee2166b779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_DNN.predict(X_test)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "plt.figure(figsize=(15, 15)) \n",
    "for i in range(10):    \n",
    "    ax = plt.subplot(2, 10, i + 1)    \n",
    "    plt.imshow(X_test[i, :, :, 0], cmap='gray')    \n",
    "    plt.title(\"Digit: {}\\nPredicted:    {}\".format(np.argmax(Y_test[i]), np.argmax(predictions[i])))    \n",
    "    plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae56570b-9e4c-452a-8e60-6e4400ff4ac0",
   "metadata": {},
   "source": [
    "**2-SGD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43bc0ea-6101-4ffb-ac9f-fb8adb7cd99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "\n",
    "def compile_model():\n",
    "    # create the model\n",
    "    model=create_DNN()\n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=SGD(),\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "print('Model compiled successfully and ready to be trained.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c43ea-f6f0-4d2b-bfcd-dcc60dcda313",
   "metadata": {},
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be546bfb-a49a-4a34-8b4e-a256f2a832e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "# create the deep neural net\n",
    "model_DNN = compile_model()\n",
    "\n",
    "# train DNN and store training info in history\n",
    "history = model_DNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3666a8a-4d00-4552-b6c2-2e009679b3e0",
   "metadata": {},
   "source": [
    "**Evaluate the Model Performance on the Unseen Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38508757-0b9d-4fa4-97c0-0f4358160be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score = model_DNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# look into training history\n",
    "fig, [ax0, ax1] = plt.subplots(1, 2, figsize=(15 , 6))\n",
    "\n",
    "# summarize history for accuracy\n",
    "ax0.plot(history.history['acc'])\n",
    "ax0.plot(history.history['val_acc'])\n",
    "ax0.set_ylabel('model accuracy')\n",
    "ax0.set_xlabel('epoch')\n",
    "ax0.legend(['train', 'test'], loc='best')\n",
    "ax0.grid()\n",
    "\n",
    "# summarize history for loss\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.plot(history.history['val_loss'])\n",
    "ax1.set_ylabel('model loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train', 'test'], loc='best')\n",
    "ax1.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ec1692-2473-466a-bb0d-cb88ec6feb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_DNN.predict(X_test)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "plt.figure(figsize=(15, 15)) \n",
    "for i in range(10):    \n",
    "    ax = plt.subplot(2, 10, i + 1)    \n",
    "    plt.imshow(X_test[i, :, :, 0], cmap='gray')    \n",
    "    plt.title(\"Digit: {}\\nPredicted:    {}\".format(np.argmax(Y_test[i]), np.argmax(predictions[i])))    \n",
    "    plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd28a816-2e17-4741-a483-3d3e2f61be34",
   "metadata": {},
   "source": [
    "**3-ADAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561ae4a-491f-4982-b2fd-9d54f8efede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "\n",
    "def compile_model():\n",
    "    # create the model\n",
    "    model=create_DNN()\n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07,),\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "print('Model compiled successfully and ready to be trained.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef811415-08ea-449d-9381-f3144a064fd3",
   "metadata": {},
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ffa91-8f29-4e79-b303-181d51ae86af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "# create the deep neural net\n",
    "model_DNN = compile_model()\n",
    "\n",
    "# train DNN and store training info in history\n",
    "history = model_DNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f36f9d-6b31-4805-93b0-c0cc873fcfef",
   "metadata": {},
   "source": [
    "**Evaluate the Model Performance on the Unseen Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b53bdea-9393-48e5-b20b-1351667105da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score = model_DNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# look into training history\n",
    "fig, [ax0, ax1] = plt.subplots(1, 2, figsize=(15 , 6))\n",
    "\n",
    "# summarize history for accuracy\n",
    "ax0.plot(history.history['acc'])\n",
    "ax0.plot(history.history['val_acc'])\n",
    "ax0.set_ylabel('model accuracy')\n",
    "ax0.set_xlabel('epoch')\n",
    "ax0.legend(['train', 'test'], loc='best')\n",
    "ax0.grid()\n",
    "\n",
    "# summarize history for loss\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.plot(history.history['val_loss'])\n",
    "ax1.set_ylabel('model loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train', 'test'], loc='best')\n",
    "ax1.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d106ae39-b7b8-4cc7-8a61-d7905c40bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_DNN.predict(X_test)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "plt.figure(figsize=(15, 15)) \n",
    "for i in range(10):    \n",
    "    ax = plt.subplot(2, 10, i + 1)    \n",
    "    plt.imshow(X_test[i, :, :, 0], cmap='gray')    \n",
    "    plt.title(\"Digit: {}\\nPredicted:    {}\".format(np.argmax(Y_test[i]), np.argmax(predictions[i])))    \n",
    "    plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a325c83-a09b-43aa-9d09-e81df3f8107b",
   "metadata": {},
   "source": [
    "Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178c46e5-630a-46eb-b5d1-00a4ba803a97",
   "metadata": {},
   "source": [
    "### Exercise 12.2\n",
    "\n",
    "Change the architecture of your DNN using convolutional layers. Use `Conv2D`, `MaxPooling2D`, `Dropout`, but also do not forget `Flatten`, a standard `Dense` layer and `soft-max` in the end. I have merged step 2 and 3 in the following definition of `create_CNN()` that **<span style=\"color:red\">you should complete</span>**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba4f07-f440-4969-9dc3-32fe5d3e82b8",
   "metadata": {},
   "source": [
    "**Creating Convolutional Neural Nets with Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e560d7-630e-438b-aff6-ff13262e8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will need the following for Convolutional Neural Networks\n",
    "from keras.layers import Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "# reshape data, depending on Keras backend\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print()\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac02854-3580-4ece-91dd-388df42718df",
   "metadata": {},
   "source": [
    "**Define the Neural Net and its Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e02760-24b6-41ed-9949-038f27552f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add first convolutional layer with 10 filters (dimensionality of output space)\n",
    "    model.add(Conv2D(10, kernel_size=(7, 7),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # add a convolution layer with 20 filters\n",
    "    model.add(Conv2D(20, kernel_size=(3, 3),\n",
    "                     activation='relu',))\n",
    "    # apply a pooliing with dimension 4x4\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    # apply a standard flat layer\n",
    "    model.add(Flatten())\n",
    "    # soft-max layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer='SGD',\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "print('Model architecture created successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea7d2c-9b06-415e-a172-088bebb9f8cd",
   "metadata": {},
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22347ba-71ce-4876-8f74-725b5b9e9f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "# create the deep neural net\n",
    "model_CNN = create_CNN()\n",
    "\n",
    "# train DNN and store training info in history\n",
    "history = model_CNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1eaf28-a2ed-4fa4-909b-664fc720d71e",
   "metadata": {},
   "source": [
    "**Evaluate the Model Performance on the Unseen Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d40114-f853-4661-8fca-25a03ae17ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score = model_CNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# look into training history\n",
    "fig, [ax0, ax1] = plt.subplots(1, 2, figsize=(15 , 6))\n",
    "\n",
    "# summarize history for accuracy\n",
    "ax0.plot(history.history['acc'])\n",
    "ax0.plot(history.history['val_acc'])\n",
    "ax0.set_ylabel('model accuracy')\n",
    "ax0.set_xlabel('epoch')\n",
    "ax0.legend(['train', 'test'], loc='best')\n",
    "ax0.grid()\n",
    "\n",
    "# summarize history for loss\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.plot(history.history['val_loss'])\n",
    "ax1.set_ylabel('model loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train', 'test'], loc='best')\n",
    "ax1.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7049f48-31d2-45d7-9e01-1487229b4ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_CNN.predict(X_test)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "plt.figure(figsize=(15, 15)) \n",
    "for i in range(10):    \n",
    "    ax = plt.subplot(2, 10, i + 1)    \n",
    "    plt.imshow(X_test[i, :, :, 0], cmap='gray')    \n",
    "    plt.title(\"Digit: {}\\nPredicted:    {}\".format(np.argmax(Y_test[i]), np.argmax(predictions[i])))    \n",
    "    plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c782c6c5-9e3b-461f-a85c-eaf7b0d9825b",
   "metadata": {},
   "source": [
    "Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746ca4c3-2f9b-428f-ac7e-4e921d8c6585",
   "metadata": {},
   "source": [
    "### Exercise 12.3\n",
    "\n",
    "Use the `gimp` application to create 10 pictures of your \"handwritten\" digits, import them in your jupyter-notebook and try to see if your CNN is able to recognize your handwritten digits.\n",
    "\n",
    "For example, you can use the following code to import a picture of an handwritten digit\n",
    "(Note: you should install Python Image Library (PIL/Pillow):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d159e189-d5d8-453c-9d15-41e9004ef38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "digit_filename = \"./7_write.png\"\n",
    "digit_in = Image.open(digit_filename).convert('L')\n",
    "\n",
    "ydim, xdim = digit_in.size\n",
    "print(\"Image size: \"+str(xdim)+\"x\"+str(ydim))\n",
    "pix=digit_in.load();\n",
    "data = np.zeros((xdim, ydim))\n",
    "for j in range(ydim):\n",
    "    for i in range(xdim):\n",
    "        data[i,j]=pix[j,i]\n",
    "\n",
    "data /= 255\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(data, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b58e685-772f-4b26-90a4-8c2880cf5dec",
   "metadata": {},
   "source": [
    "**Use the previous trained neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed585f6b-a424-4418-8a5f-2698515d3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data = data.reshape(1,xdim,ydim,1)\n",
    "print(data.shape)\n",
    "pred_8 = model_CNN.predict(data)\n",
    "\n",
    "data = data.reshape(xdim,ydim)\n",
    "\n",
    "plt.figure(figsize=(5, 5))  \n",
    "plt.imshow(data, cmap='gray')    \n",
    "plt.title(\"Digit predicted:    {}\".format(np.argmax(pred_8)))\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b06524-e67f-40d9-9add-cd67a292cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_filename = \"./5_write.png\"\n",
    "digit_in = Image.open(digit_filename).convert('L')\n",
    "\n",
    "ydim, xdim = digit_in.size\n",
    "print(\"Image size: \"+str(xdim)+\"x\"+str(ydim))\n",
    "pix=digit_in.load();\n",
    "data = np.zeros((xdim, ydim))\n",
    "for j in range(ydim):\n",
    "    for i in range(xdim):\n",
    "        data[i,j]=pix[j,i]\n",
    "\n",
    "data /= 255\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(data, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32613e14-0e5f-4c65-b663-76decbad6dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data = data.reshape(1,xdim,ydim,1)\n",
    "print(data.shape)\n",
    "pred_8 = model_CNN.predict(data)\n",
    "\n",
    "data = data.reshape(xdim,ydim)\n",
    "\n",
    "plt.figure(figsize=(5, 5))  \n",
    "plt.imshow(data, cmap='gray')    \n",
    "plt.title(\"Digit predicted:    {}\".format(np.argmax(pred_8)))\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f988a906-a9ad-41f5-a9ec-3d409f660cbd",
   "metadata": {},
   "source": [
    "Comment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
