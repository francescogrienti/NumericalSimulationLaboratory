{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e2bc297-6849-4e6c-8557-99ab1a7d36e4",
   "metadata": {},
   "source": [
    "**EXERCISE_12**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b2df0a-270b-4b7a-a57c-cb7d49d9410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "seed=0\n",
    "np.random.seed(seed) # fix random seed\n",
    "tf.random.set_seed(seed)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93c8ad4d-e01d-48f7-b0ea-fb5ae5bbd20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n",
      "X_train shape: (60000, 28, 28)\n",
      "Y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28 # number of pixels \n",
    "# output\n",
    "num_classes = 10 # 10 digits\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62e1827b-a63c-479d-86f6-56d52a05bf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 784)\n",
      "X_test shape: (10000, 784)\n",
      "\n",
      "an example of a data point with label 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... and with label [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] after to_categorical\n",
      "\n",
      "X_train shape: (60000, 784)\n",
      "Y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# reshape data, it could depend on Keras backend\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows*img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows*img_cols)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print()\n",
    "\n",
    "# cast to floats\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# rescale data in interval [0,1]\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# look at an example of data point\n",
    "print('an example of a data point with label', Y_train[22])\n",
    "# matshow: display a matrix in a new figure window\n",
    "plt.matshow(X_train[22,:].reshape(28,28),cmap='binary')\n",
    "plt.show()\n",
    "\n",
    "# convert class vectors to binary class matrices, e.g. for use with categorical_crossentropy\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "print('... and with label', Y_train[22], 'after to_categorical')\n",
    "print()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb881cfa-7a45-4425-bf85-7d4d745a422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture created successfully!\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "def create_DNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(400,input_shape=(img_rows*img_cols,), activation='relu'))\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # soft-max layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "print('Model architecture created successfully!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cbcf82f-dc99-4caf-a2ff-705e3e41f7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully and ready to be trained.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "\n",
    "def compile_model():\n",
    "    # create the model\n",
    "    model=create_DNN()\n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=tf.keras.optimizers.legacy.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0),\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "print('Model compiled successfully and ready to be trained.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea4a8de4-e111-4284-ab99-c2291f79b094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adadelta.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "decay is deprecated in the new Keras optimizer, please check the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.Adadelta.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# create the deep neural net\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m model_DNN \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# train DNN and store training info in history\u001b[39;00m\n\u001b[1;32m      9\u001b[0m history \u001b[38;5;241m=\u001b[39m model_DNN\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train,\n\u001b[1;32m     10\u001b[0m           batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     11\u001b[0m           epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m     12\u001b[0m           verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     13\u001b[0m           validation_data\u001b[38;5;241m=\u001b[39m(X_test, Y_test))\n",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m, in \u001b[0;36mcompile_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m=\u001b[39mcreate_DNN()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# compile the model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mcategorical_crossentropy,\n\u001b[0;32m----> 8\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39m\u001b[43mAdadelta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      9\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/optimizers/adadelta.py:82\u001b[0m, in \u001b[0;36mAdadelta.__init__\u001b[0;34m(self, learning_rate, rho, epsilon, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, name, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     68\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     81\u001b[0m ):\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclipnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclipvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclipvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mglobal_clipnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_clipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_ema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_ema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mema_momentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mema_momentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mema_overwrite_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mema_overwrite_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjit_compile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjit_compile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_learning_rate(learning_rate)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrho \u001b[38;5;241m=\u001b[39m rho\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:1084\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m mesh \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmesh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mesh \u001b[38;5;241m=\u001b[39m mesh\n\u001b[0;32m-> 1084\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclipvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_clipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_ema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mema_momentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mema_overwrite_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjit_compile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_with_dtensor \u001b[38;5;241m=\u001b[39m dtensor_utils\u001b[38;5;241m.\u001b[39mrunning_with_dtensor_strategy()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:106\u001b[0m, in \u001b[0;36m_BaseOptimizer.__init__\u001b[0;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_iteration_variable()\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:135\u001b[0m, in \u001b[0;36m_BaseOptimizer._process_kwargs\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m legacy_kwargs:\n\u001b[0;32m--> 135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    136\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated in the new Keras optimizer, please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck the docstring for valid arguments, or use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy optimizer, e.g., \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.keras.optimizers.legacy.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         )\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    143\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid argument, kwargs should be empty \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for `optimizer_experimental.Optimizer`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: decay is deprecated in the new Keras optimizer, please check the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.Adadelta."
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "# create the deep neural net\n",
    "model_DNN = compile_model()\n",
    "\n",
    "# train DNN and store training info in history\n",
    "history = model_DNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d0f65-6401-4a13-a392-a31eb7f2664c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
